{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import math\n",
    "import random\n",
    "import csv\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.layers as layers\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = './pre-traffic-signs-data/pre-data.pickle'\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    pickle_data = pickle.load(f)\n",
    "    X_train = pickle_data['train_features']\n",
    "    y_train = pickle_data['train_labels']\n",
    "    X_valid = pickle_data['valid_features']\n",
    "    y_valid = pickle_data['valid_labels']\n",
    "    X_test = pickle_data['test_features']\n",
    "    y_test = pickle_data['test_labels']\n",
    "    signnames = pickle_data['signnames']\n",
    "    del pickle_data \n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "X_valid, y_valid = shuffle(X_valid, y_valid)\n",
    "X_test, y_test = shuffle(X_test, y_test)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_valid.shape, y_valid.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "print(len(signnames))\n",
    "print('Data loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Inception(inputs, conv11_size, conv33_11_size, conv33_size,conv55_11_size, conv55_size, pool11_size):\n",
    "    conv11 = layers.conv2d(inputs, conv11_size, [1, 1])\n",
    "    conv33_reduce = layers.conv2d(inputs, conv33_11_size, [1, 1])\n",
    "    conv33 = layers.conv2d(conv33_reduce, conv33_size, [3, 3])\n",
    "    conv55_reduce = layers.conv2d(inputs, conv55_11_size, [1, 1])\n",
    "    conv55 = layers.conv2d(conv55_reduce, conv55_size, [5, 5])\n",
    "    pool_proj = layers.max_pool2d(inputs, [3, 3], stride = 1, padding='SAME')\n",
    "    pool11 = layers.conv2d(pool_proj, pool11_size, [1, 1])\n",
    "    return tf.concat([conv11, conv33, conv55, pool11], 3)\n",
    "\n",
    "def GoogLeNet(inputs, dropout_keep_prob): \n",
    "    conv1 = layers.conv2d(inputs, 64, [3, 3], stride = 2) \n",
    "    \n",
    "    inception_2a = Inception(conv1, 64, 96, 128, 16, 32, 32) \n",
    "    inception_2b = Inception(inception_2a, 128, 128, 192, 32, 96, 64) \n",
    "    pool2 = layers.max_pool2d(inception_2b, [3, 3]) \n",
    "    \n",
    "    inception_3a = Inception(pool2, 192, 96, 208, 16, 48, 64) \n",
    "    inception_3b = Inception(inception_3a, 160, 112, 224, 24, 64, 64)\n",
    "    pool3 = layers.max_pool2d(inception_3b, [3, 3]) \n",
    "    \n",
    "    inception_4a = Inception(pool3, 256, 160, 320, 32, 128, 128)\n",
    "    inception_4b = Inception(inception_4a, 384, 192, 384, 48, 128, 128)\n",
    "    pool4 = layers.avg_pool2d(inception_4b, [3, 3], stride = 1) \n",
    "\n",
    "    reshape = tf.reshape(pool4, [-1, 1024])\n",
    "    dropout = layers.dropout(reshape, dropout_keep_prob)\n",
    "    logits = layers.fully_connected(dropout, 43, activation_fn=None)\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y = tf.one_hot(y, 43)\n",
    "keep_prob = tf.placeholder_with_default(1.0, shape=())\n",
    "\n",
    "\n",
    "LEARNING_RATE = 4e-4\n",
    "EPOCHS = 35\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "\n",
    "logits = GoogLeNet(x, keep_prob)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
    "loss_op = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = LEARNING_RATE)\n",
    "train_op = optimizer.minimize(loss_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_op = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset + BATCH_SIZE], y_data[offset:offset + BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_op, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "train_accuracy = []\n",
    "valid_accuracy = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    print(\"Training...\")\n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        total_train_acc = 0\n",
    "        print(\"EPOCH {} :\".format(i+1), end=' ')\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            _, train_acc = sess.run([train_op, accuracy_op], feed_dict={x: batch_x, y: batch_y, keep_prob: 0.5})\n",
    "            total_train_acc += (train_acc * len(batch_x))\n",
    "        train_accuracy.append(total_train_acc / num_examples)\n",
    "        valid_acc = evaluate(X_valid, y_valid)\n",
    "        valid_accuracy.append(valid_acc)\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(valid_acc))\n",
    "        \n",
    "    saver.save(sess, './model/googlenet.ckpt')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(train_accuracy, label='train')\n",
    "plt.plot(valid_accuracy, label='valid')\n",
    "plt.title('Accuracy history')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.gcf().set_size_inches(15, 15)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.import_meta_graph('./model/googlenet.ckpt.meta')\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, './model/googlenet.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, './model/googlenet.ckpt')\n",
    "    train_accuracy = evaluate(X_train, y_train)\n",
    "    valid_accuracy = evaluate(X_valid, y_valid)\n",
    "    test_accuracy = evaluate(X_test, y_test)\n",
    "    \n",
    "accuracys = [train_accuracy, valid_accuracy, test_accuracy]\n",
    "tick_labels = [\"training set\", \"validation set\", \"testing set\"]\n",
    "plt.bar(range(3), accuracys)\n",
    "plt.xlabel('data set')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xticks(range(3), tick_labels)\n",
    "for x_,y_ in zip(range(3), accuracys):\n",
    "    plt.text(x_ - 0.1, y_, '%.3f'%y_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_images = []\n",
    "online_labels = [0, 9, 12, 14, 17, 22, 25, 26, 31, 35]\n",
    "\n",
    "for i in range(1, 11):\n",
    "    image = plt.imread('./test_images/' + str(i) +'.jpeg')\n",
    "    image_reshape = cv2.resize(image,(32, 32), interpolation = cv2.INTER_CUBIC)\n",
    "    online_images.append(image_reshape)\n",
    "\n",
    "plt.figure(figsize=(25, 10))\n",
    "plt.subplots_adjust(hspace = .1, wspace=.1)\n",
    "for i in range(len(online_images)):\n",
    "    plt.subplot(1, 10, i + 1)\n",
    "    plt.imshow(online_images[i])\n",
    "    plt.title(signnames[int(online_labels[i])])\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "plt.savefig('./result_images/online image.jpg')\n",
    "\n",
    "online_images = np.array(online_images)\n",
    "online_images = online_images.astype(np.float32) / 128. - 1.\n",
    "online_labels = np.array(online_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, './model/googlenet.ckpt')\n",
    "    test_accuracy = evaluate(online_images, online_labels)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))   \n",
    "    logits_value = sess.run(logits, feed_dict={x: online_images})\n",
    "    probabilities = sess.run(tf.nn.softmax(logits_value))\n",
    "    \n",
    "predict = probabilities.argmax(axis=1)\n",
    "print(\"pred\")\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    top5 = sess.run(tf.nn.top_k(tf.constant(probabilities), k=30)) #change k for more images\n",
    "\n",
    "values = top5.values\n",
    "indices = top5.indices\n",
    "fig, axes = plt.subplots(2, 5, figsize=(25, 8))\n",
    "for i in range(2):\n",
    "    for j in range(5):\n",
    "        axes[i][j].bar(range(5), values[i*5+j])\n",
    "        axes[i][j].set_xticklabels(indices[i*5+j])\n",
    "        axes[i][j].set_title(\"answer: \"+str(online_labels[i*5+j]))\n",
    "        for x_,y_ in zip(range(5), values[i*5+j]):\n",
    "            axes[i][j].text(x_ - 0.25, y_, '%.3f'%y_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
